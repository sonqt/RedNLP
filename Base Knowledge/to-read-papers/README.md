# To Read Papers

This is a list of papers to read in preparation for our 2022 summer research in NLP. 

## The development of SQuAD (core)
* SQuAD: 100,000+ Questions for Machine Comprehension of Text
* Reading Wikipedia to Answer Open-Domain Questions
* Adversarial Examples for Evaluating Reading Comprehension Systems
* Evaluation Metrics for Machine Reading Comprehension: Prerequisite Skills and Readability
* What Makes Reading Comprehension Questions Easier?
* SQuAD 2.0: Know what you don’t know: Unanswerable Questions for SQuAD.
* Challenges in Information-Seeking QA: Unanswerable questions and Paragraph Retrieval
* Different Aspects of Unanswerable questions (based on results in Son’s current researches) 
* Coreference Reasoning in Machine Reading Comprehension 
* Benchmarking Machine Reading Comprehension: A Psychological Perspective


## Dataset
* Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension

## Adversarial attacks
* Using Adversarial Attacks to Reveal the Statistical Bias in Machine Reading Comprehension Models

## Shortcut learning
* Why Machine Reading Comprehension Models Learn Shortcuts? 
* Towards Interpreting and Mitigating Shortcut Learning Behavior of NLU models
* Avoiding Reasoning Shortcuts: Adversarial Evaluation, Training, and Model Development

## MRC techniques







